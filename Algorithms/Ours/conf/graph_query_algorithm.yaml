# mongodb
dbname: mydatabase
username: root
password: 1234
port: 27017

# input
qa_dataset_path: /mnt/sdf/OTT-QAMountSpace/Dataset/COS/ott_dev_q_to_tables_with_bm25neg.json
edge_dataset_path: /mnt/sdd/shpark/preprocess_table_graph_cos_apply_topk_edge_1.jsonl
table_data_path: /mnt/sdf/OTT-QAMountSpace/Dataset/COS/ott_table_chunks_original.json
passage_data_path: /mnt/sdf/OTT-QAMountSpace/Dataset/COS/ott_wiki_passages.json
entity_linking_dataset_path: /mnt/sdd/shpark/table_chunks_to_passages_cos_table_passage.jsonl

# output
final_result_path: /mnt/sdf/OTT-QAMountSpace/ExperimentResults/graph_query_algorithm/Table_Schema.jsonl
query_time_save_path: /mnt/sdf/OTT-QAMountSpace/ExperimentResults/graph_query_algorithm/Table_Schema_time.json
error_cases_save_path: /mnt/sdf/OTT-QAMountSpace/ExperimentResults/graph_query_algorithm/Table_Schema_error.json

# retriever
## id to chunk id
edge_ids_path: /mnt/sdf/OTT-QAMountSpace/Dataset/Ours/Embedding_Dataset/edge/top_1/index_to_chunk_id_edge_topk_1.json
table_ids_path: /mnt/sdf/OTT-QAMountSpace/Dataset/Ours/Embedding_Dataset/table_cos_version/index_to_chunk_id.json
passage_ids_path: /mnt/sdf/OTT-QAMountSpace/Dataset/Ours/Embedding_Dataset/passage_cos_version/index_to_chunk_id.json

## colbert config
collection_edge_path: /mnt/sdf/OTT-QAMountSpace/Dataset/Ours/Embedding_Dataset/edge/top_1/edge_topk_1.tsv
collection_table_path: /mnt/sdf/OTT-QAMountSpace/Dataset/Ours/Embedding_Dataset/table_cos_version/collection.tsv
collection_passage_path: /mnt/sdf/OTT-QAMountSpace/Dataset/Ours/Embedding_Dataset/passage_cos_version/collection.tsv

edge_index_root_path: /mnt/sdc/shpark/OTT-QAMountSpace/Embeddings
table_index_root_path: /mnt/sdc/shpark/OTT-QAMountSpace/Embeddings
passage_index_root_path: /mnt/sdc/shpark/OTT-QAMountSpace/Embeddings

edge_index_name: top1_edge_embeddings_v2_trained_1_epoch_bsize_512
table_index_name: passage_to_table_segment_embeddings_trained_w_sample_rate_0_3_cos_version_query_len_96
passage_index_name: table_segment_to_passage_embeddings_trained_w_sample_rate_0_5_cos_version_query_len_96

edge_checkpoint_path: /mnt/sdf/OTT-QAMountSpace/ModelCheckpoints/Ours/ColBERT/edge_trained_v2
table_checkpoint_path: /mnt/sdf/OTT-QAMountSpace/ModelCheckpoints/Ours/ColBERT/passage_to_table_segment_sample_rate_0_3_query_len_96
passage_checkpoint_path: /mnt/sdf/OTT-QAMountSpace/ModelCheckpoints/Ours/ColBERT/table_segment_to_passage_sample_rate_0_5_query_len_96
reranker_checkpoint_path: /mnt/sdf/OTT-QAMountSpace/ModelCheckpoints/Ours/Merged_BAAI_RERANKER_15_96_ckpt_400
llm_checkpoint_path: /mnt/sdf/OTT-QAMountSpace/ModelCheckpoints/Ours/llm/TechxGenus/Meta-Llama-3-70B-Instruct-AWQ

nbits: 2

# experimental setting
top_k_of_edge: 150
top_k_of_table_segment_augmentation: 10
top_k_of_passage_augmentation: 0
top_k_of_table_segment: 0
top_k_of_passage: 2
top_k_of_table_select_w_llm: 3
node_scoring_method: max
edge_reranker_batch_size: 150

# table retrieval setting
defaults:
  - encoder: hf_bert # defines encoder initialization parameters

indexers:
  flat:
    _target_: dpr.indexer.faiss_indexers.DenseFlatIndexer

  hnsw:
    _target_: dpr.indexer.faiss_indexers.DenseHNSWFlatIndexer

  hnsw_sq:
    _target_: dpr.indexer.faiss_indexers.DenseHNSWSQIndexer

# a list of names of the passages datasets from the 'ctx_sources' config group
ctx_datatsets: [/mnt/sdf/OTT-QAMountSpace/Dataset/COS/ott_table_chunks_original.json,/mnt/sdf/OTT-QAMountSpace/Dataset/COS/ott_wiki_passages.json,[/mnt/sdf/OTT-QAMountSpace/Dataset/COS/EntityLinkingResults_GivenByAuthor/table_chunks_to_passages*]]

#Glob paths to encoded passages (from generate_dense_embeddings tool)
encoded_ctx_files: [/mnt/sdf/OTT-QAMountSpace/Embeddings/COS/ott_table_original*]

out_file:
# "regex" or "string"
match: string
n_docs: 100
validation_workers: 16

num_shards: 1
shard_id: 0
hop1_limit: 200
hop1_keep: 30
hop2_limit: 50
do_retrieve: False
do_link: False 
do_span: False
do_cos: True
hop2_expert: 4
mean_pool: False

# Whether to lower case the input text. Set True for uncased models, False for the cased ones.
do_lower_case: True

# The attribute name of encoder to use for queries. Options for the BiEncoder model: question_model, ctx_model
# question_model is used if this param is empty
encoder_path:

# path to the FAISS index location - it is only needed if you want to serialize faiss index to files or read from them
# (instead of using encoded_ctx_files)
# it should point to either directory or a common index files prefix name
# if there is no index at the specific location, the index will be created from encoded_ctx_files
index_path:

kilt_out_file:
table_chunk_file:
label_question: False
# A trained bi-encoder checkpoint file to initialize the model
model_file: /mnt/sdf/OTT-QAMountSpace/ModelCheckpoints/COS/cos_nq_ott_hotpot_finetuned_6_experts.ckpt

validate_as_tables: False
rpc_retriever_cfg_file:
indexer: flat

# tokens which won't be slit by tokenizer
special_tokens:

# TODO: move to a conf group
# local_rank for distributed training on gpus
local_rank: -1
global_loss_buf_sz: 150000
device:
distributed_world_size:
no_cuda: False
n_gpu:
fp16: False

# For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']."
#        "See details at https://nvidia.github.io/apex/amp.html
fp16_opt_level: O1