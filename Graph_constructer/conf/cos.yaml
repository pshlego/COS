defaults:
  - encoder: hf_bert

result_path: /mnt/sdd/shpark/graph/entity_linking_results/table_chunks_to_passages_cos.json

table:
  embedding_path: /mnt/sdd/shpark/cos/embeds/ott_table_original_0 
  mention_path: /mnt/sdd/shpark/graph/for_test/all_table_chunks_span_prediction.json
  question_embedding_path: /mnt/sdd/shpark/cos/embeds/ott_table_question_0

passage:
  embedding_path: /mnt/sdd/shpark/cos/embeds/ott_wiki_linker_0
  mention_path: /mnt/sdd/shpark/graph/for_test/all_passage_chunks_span_prediction.json
  question_embedding_path: /mnt/sdd/shpark/cos/embeds/ott_passage_question_0

# top k entities to retrieve
k: 2

# A trained bi-encoder checkpoint file to initialize the model
model_file: /mnt/sdd/shpark/cos/models/cos_nq_ott_hotpot_finetuned_6_experts.ckpt
expert_id: 2
batch_size: 256
num_shards: 1

# Batch size to generate query embeddings
do_link: True

# Whether to lower case the input text. Set True for uncased models, False for the cased ones.
do_lower_case: True
special_tokens:
encoder_path:

# local_rank for distributed training on gpus
device_id: 0
local_rank: -1
device:
distributed_world_size:
no_cuda: False
n_gpu:
fp16: False
