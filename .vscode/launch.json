{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [

        {
            "name": "training",
            "type": "python",
            "request": "launch",
            //"module": "torch.distributed.launch",
            "program": "/home/shpark/anaconda3/envs/hf4/bin/torchrun",
            "console": "integratedTerminal",
            "python":"/home/shpark/anaconda3/envs/hf4/bin/python",
            "args":[
                "--nproc_per_node", "2", "-m","FlagEmbedding.llm_reranker.finetune_for_layerwise.run",
                "--output_dir", "/mnt/sdf/shpark/OTT-QAMountSpace/OTT-QAMountSpace/ModelCheckpoints/Ours/reranker-baai",
                "--model_name_or_path", "BAAI/bge-reranker-v2-minicpm-layerwise",
                "--train_data", "/mnt/sdf/shpark/OTT-QAMountSpace/OTT-QAMountSpace/Dataset/Ours/Training_Dataset/edge/reranking_edge.jsonl",
                "--learning_rate", "2e-4",
                "--num_train_epochs", "1",
                "--per_device_train_batch_size", "1",
                "--gradient_accumulation_steps", "2",
                "--dataloader_drop_last", "True",
                "--query_max_len", "512",
                "--passage_max_len", "512",
                "--train_group_size", "16",
                "--logging_steps", "1",
                "--save_steps", "50",
                "--save_total_limit", "50",
                "--ddp_find_unused_parameters", "False",
                "--gradient_checkpointing",
                "--deepspeed", "/mnt/sdf/shpark/OTT-QAMountSpace/OTT-QAMountSpace/ModelCheckpoints/Ours/stage1.json",
                "--warmup_ratio", "0.1",
                "--bf16",
                "--use_lora", "True",
                "--lora_rank", "32",
                "--lora_alpha", "64",
                "--use_flash_attn", "True",
                "--target_modules", "q_proj k_proj v_proj o_proj",
                "--start_layer", "8",
                "--head_multi", "True",
                "--head_type", "simple",
                "--lora_extra_parameters", "linear_head",
                "--finetune_type", "from_finetuned_model"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "2,3",
                // "PYTHONPATH": "/home/shpark/anaconda3/envs/hf4/lib/python3.8/site-packages/FlagEmbedding"
            },
            "justMyCode": false,
        },
    ]
}